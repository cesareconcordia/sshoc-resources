{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking citations in DH Conference papers\n",
    "\n",
    "This notebook presents some basic results obtained extracting citations from the abstracts of *(ADHO) DH conferences* from 2015 to 2020 and  from *DHQ journal* articles. The complete dataset is available [here](https://github.com/lehkost/ToolXtractor/)\n",
    "\n",
    "\n",
    "- [Import Dataset](#Import-the-Dataset)\n",
    "- [Find DOIs in references](#Find-citations-having-a-DOI)\n",
    "- [Check DOIs](#Check-DOIs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tei(tei_file):\n",
    "    with open(tei_file, 'r') as tei:\n",
    "        soup = BeautifulSoup(tei, 'lxml')\n",
    "        return soup\n",
    "    raise RuntimeError('Cannot generate a soup from the input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elem_to_text(elem, default=''):\n",
    "    if elem:\n",
    "        return elem.getText(separator=' ', strip=True)\n",
    "    else:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Person:\n",
    "    firstname: str\n",
    "    middlename: str\n",
    "    surname: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEIFile(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.soup = read_tei(filename)\n",
    "        self._text = None\n",
    "        self._title = ''\n",
    "        self._abstract = ''\n",
    "\n",
    "    @property\n",
    "    def doi(self):\n",
    "        idno_elem = self.soup.find('idno', type='DOI')\n",
    "        if not idno_elem:\n",
    "            return ''\n",
    "        else:\n",
    "            return idno_elem.getText()\n",
    "\n",
    "    @property\n",
    "    def title(self):\n",
    "        if not self._title:\n",
    "            if  not self.soup.title:\n",
    "                self._title = \"na\"\n",
    "            else:\n",
    "                self._title = self.soup.title.getText().replace('\\n','').strip()\n",
    "        return self._title\n",
    "\n",
    "    @property\n",
    "    def abstract(self):\n",
    "        if not self._abstract:\n",
    "            abstract = self.soup.abstract.getText(separator=' ', strip=True)\n",
    "            self._abstract = abstract\n",
    "        return self._abstract\n",
    "\n",
    "    @property\n",
    "    def authors(self):\n",
    "        #authors_in_header = self.soup.analytic.find_all('author')\n",
    "        authors_in_header = self.soup.find_all('author')\n",
    "\n",
    "        result = []\n",
    "        for author in authors_in_header:\n",
    "            persname = author.persname\n",
    "            if not persname:\n",
    "                continue\n",
    "            firstname = elem_to_text(persname.find(\"forename\"))#, type=\"first\"))\n",
    "            middlename = elem_to_text(persname.find(\"forename\", type=\"middle\"))\n",
    "            surname = elem_to_text(persname.surname)\n",
    "            person = Person(firstname, middlename, surname)\n",
    "            result.append(person)\n",
    "        return result\n",
    "    \n",
    "    @property\n",
    "    def bibliography(self):\n",
    "        bibliography = self.soup.find_all('bibl')\n",
    "        result = []\n",
    "        for bibl in bibliography:\n",
    "            if not bibl:\n",
    "                continue\n",
    "            if (elem_to_text(bibl).startswith(\"DHQ classification\")):\n",
    "                continue\n",
    "            if (elem_to_text(bibl).startswith(\"Keywords supplied by author\")):\n",
    "                continue\n",
    "            if (elem_to_text(bibl).startswith(\"(accessed )\")):\n",
    "                continue\n",
    "            if (elem_to_text(bibl).startswith(\"Enter your references here\")):\n",
    "                continue\n",
    "            my_bibl_tmp=elem_to_text(bibl).replace('\\n','').strip()\n",
    "            ref = bibl.ref\n",
    "            lref=\"\";\n",
    "            ptref=\"\";\n",
    "            if ref:\n",
    "                lref=ref['target'].strip();\n",
    "                #print ('ref '+ref['target'])\n",
    "            ptr = bibl.ptr\n",
    "            if ptr:\n",
    "                ptref=ptr['target'].strip();\n",
    "                if lref!=\"\" and (\"\".join(lref.split())).lower()!=(\"\".join(ptref.split()).lower()):\n",
    "                    lref=lref+\" \"+ptref;\n",
    "                    #print ('ptr '+ptr['target'])\n",
    "            if lref!=\"\" and lref.lower() not in my_bibl_tmp.lower():\n",
    "                my_bibl_tmp=my_bibl_tmp+\" \"+(\"\".join(lref.split()))\n",
    "            \n",
    "            my_bibl_tmp=my_bibl_tmp.replace(' .', '.')\n",
    "            #print (my_bibl_tmp)\n",
    "            result.append(\" \".join(my_bibl_tmp.split()))\n",
    "        return result\n",
    "\n",
    "\n",
    "    @property\n",
    "    def text(self):\n",
    "        if not self._text:\n",
    "            divs_text = []\n",
    "            for div in self.soup.body.find_all(\"div\"):\n",
    "                # div is neither an appendix nor references, just plain text.\n",
    "                if not div.get(\"type\"):\n",
    "                    div_text = div.get_text(separator=' ', strip=True)\n",
    "                    divs_text.append(div_text)\n",
    "\n",
    "            plain_text = \" \".join(divs_text)\n",
    "            self._text = plain_text\n",
    "        return self._text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citation_cn (df_dois_values, default=''):\n",
    "    df_cn_citations = pd.DataFrame (columns = ['doi','cn_citation']);\n",
    "    import requests;\n",
    "    headers_dict = {\"Accept\": \"text/x-bibliography\", \"locale\":\"en-EN\"};\n",
    "    for vard in df_orig_dois_values:\n",
    "        if ( vard != \"\" and vard!=None):\n",
    "            print(vard)\n",
    "            try:\n",
    "                rd =requests.get(\"http://doi.org/\"+vard, headers=headers_dict, timeout=20)\n",
    "                # print(\"result: \"+r.content.decode(\"utf-8\"))\n",
    "                if ('DOI Not Found'in rd.text):\n",
    "                    df_cn_citations = df_cn_citations.append({'doi': vard, 'cn_citation': 'Not Found'}, ignore_index=True)\n",
    "                else:\n",
    "                    df_cn_citations = df_cn_citations.append({'doi': vard, 'cn_citation': rd.content.decode(\"latin-1\")}, ignore_index=True)\n",
    "            except requests.exceptions.ConnectionError:\n",
    "              #  print(var)\n",
    "                df_cn_citations = df_cn_citations.append({'doi': vard, 'cn_citation': int(503)}, ignore_index=True)\n",
    "            except requests.exceptions.ConnectTimeout:\n",
    "              #  print(var)\n",
    "                df_cn_citations = df_cn_citations.append({'doi': vard, 'cn_citation': int(408)}, ignore_index=True)\n",
    "            except requests.exceptions.ReadTimeout:\n",
    "                df_cn_citations = df_cn_citations.append({'doi': vard, 'cn_citation': int(408)}, ignore_index=True)\n",
    "        else:\n",
    "           # print(var ,0)\n",
    "            df_cn_citations = df_cn_citations.append({'doi': 'none', 'cn_citation': int(400)}, ignore_index=True)\n",
    "    return df_cn_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citation_from_SSHOC (df_dois_values, default=''):\n",
    "    df_cn_citations = pd.DataFrame (columns = ['doi','cn_citation']);\n",
    "    import requests;\n",
    "    #headers_dict = {\"Accept\": \"text/x-bibliography\", \"locale\":\"en-EN\"};\n",
    "    for vard in df_dois_values:\n",
    "        if ( vard != \"\" and vard!=None):\n",
    "            print(vard)\n",
    "            try:\n",
    "                rd =requests.get(\"http://v4e-lab.isti.cnr.it/citationservice/citharvester/getmetadatahtml?pid=https://doi.org/\"+vard+\"&token=test\", timeout=75)\n",
    "                #print(\"result: \"+rd.content.decode(\"latin-1\"))\n",
    "                if ('DOI Not Found'in rd.text):\n",
    "                    df_cn_citations = df_cn_citations.append({'doi': vard, 'cn_citation': 'Not Found'}, ignore_index=True)\n",
    "                else:\n",
    "                    df_cn_citations = df_cn_citations.append({'doi': vard, 'cn_citation': rd.content.decode(\"latin-1\")}, ignore_index=True)\n",
    "            except requests.exceptions.ConnectionError:\n",
    "              #  print(var)\n",
    "                df_cn_citations = df_cn_citations.append({'doi': vard, 'cn_citation': int(503)}, ignore_index=True)\n",
    "            except requests.exceptions.ConnectTimeout:\n",
    "              #  print(var)\n",
    "                df_cn_citations = df_cn_citations.append({'doi': vard, 'cn_citation': int(408)}, ignore_index=True)\n",
    "            except requests.exceptions.ReadTimeout:\n",
    "                df_cn_citations = df_cn_citations.append({'doi': vard, 'cn_citation': int(408)}, ignore_index=True)\n",
    "        else:\n",
    "           # print(var ,0)\n",
    "            df_cn_citations = df_cn_citations.append({'doi': 'none', 'cn_citation': int(400)}, ignore_index=True)\n",
    "    return df_cn_citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HTTP_Status(urls):\n",
    "    import requests;\n",
    "    df_http_status = pd.DataFrame (columns = ['DOI','status'])\n",
    "    for var in urls:\n",
    "        #print(var)\n",
    "        if ( var != \"\"):\n",
    "            try:\n",
    "                r =requests.get(\"https://doi.org/\"+var,timeout=21)\n",
    "                print(\"result: \"+var+ \" \",r.status_code)\n",
    "                df_http_status = df_http_status.append({'DOI': var, 'status': int(r.status_code)}, ignore_index=True)\n",
    "            except requests.exceptions.ConnectionError:\n",
    "              #  print(var)\n",
    "                df_http_status = df_http_status.append({'DOI': var, 'status': int(503)}, ignore_index=True)\n",
    "            except requests.exceptions.ConnectTimeout:\n",
    "                df_http_status = df_http_status.append({'DOI': var, 'status': int(408)}, ignore_index=True)\n",
    "            except requests.exceptions.ReadTimeout:\n",
    "                df_http_status = df_http_status.append({'DOI': var, 'status': int(408)}, ignore_index=True)\n",
    "            except requests.exceptions.RequestException:\n",
    "                df_http_status = df_http_status.append({'DOI': var, 'status': int(500)}, ignore_index=True)\n",
    "            except TypeError:\n",
    "                df_http_status = df_http_status.append({'DOI': var, 'status': int(400)}, ignore_index=True)\n",
    "        else:\n",
    "            df_http_status = df_http_status.append({'DOI': var, 'status': int(400)}, ignore_index=True)\n",
    "    return df_http_status;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename, splitext\n",
    "\n",
    "def basename_without_ext(path):\n",
    "    base_name = basename(path)\n",
    "    stem, ext = splitext(base_name)\n",
    "    if stem.endswith('.tei'):\n",
    "        # Return base name without tei file\n",
    "        return stem[0:-4]\n",
    "    else:\n",
    "        return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tei_to_csv_entry(tei_file):\n",
    "    tei = TEIFile(tei_file)\n",
    "    #print(f\"Handled {tei_file}\")\n",
    "    base_name = basename_without_ext(tei_file)\n",
    "    return base_name, tei.authors, tei.title, tei.bibliography#, tei.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import Pool\n",
    "pool = Pool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Dataset\n",
    "\n",
    "The dataset of DH conference abstracts (2016-20020) and DHQ articles is downloaded from https://github.com/lehkost/ToolXtractor/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "papers15 = sorted(Path(\"/Users/cesare/git/SSHOCCitationService/dataset/ToolXtractor/data/DH/xml/2015/\").glob('*.xml'))\n",
    "papers16 = sorted(Path(\"/Users/cesare/git/SSHOCCitationService/dataset/ToolXtractor/data/DH/xml/2016/\").glob('*.xml'))\n",
    "papers17 = sorted(Path(\"/Users/cesare/git/SSHOCCitationService/dataset/ToolXtractor/data/DH/xml/2017/\").glob('*.xml'))\n",
    "papers18 = sorted(Path(\"/Users/cesare/git/SSHOCCitationService/dataset/ToolXtractor/data/DH/xml/2018/\").glob('*.xml'))\n",
    "papers19 = sorted(Path(\"/Users/cesare/git/SSHOCCitationService/dataset/ToolXtractor/data/DH/xml/2019/\").glob('*.xml'))\n",
    "papers20 = sorted(Path(\"/Users/cesare/git/SSHOCCitationService/dataset/ToolXtractor/data/DH/xml/2020/\").glob('*.xml'))\n",
    "papersdhq = sorted(Path(\"/Users/cesare/git/SSHOCCitationService/dataset/ToolXtractor/data/DHQ/\").glob('*.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_entries15 = pool.map(tei_to_csv_entry, papers15)\n",
    "csv_entries16 = pool.map(tei_to_csv_entry, papers16)\n",
    "csv_entries17 = pool.map(tei_to_csv_entry, papers17)\n",
    "csv_entries18 = pool.map(tei_to_csv_entry, papers18)\n",
    "csv_entries19 = pool.map(tei_to_csv_entry, papers19)\n",
    "csv_entries20 = pool.map(tei_to_csv_entry, papers20)\n",
    "csv_entriesdhq=pool.map(tei_to_csv_entry, papersdhq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test=tei_to_csv_entry(\"/Users/cesare/git/SSHOCCitationService/data/DHQ/000019.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              2788\n",
       "Authors         2788\n",
       "Title           2788\n",
       "Bibliography    2788\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_csv0 = pd.DataFrame(csv_entries15, columns=['ID', 'Authors', 'Title', 'Bibliography'])\n",
    "result_csv1 = result_csv0.append(pd.DataFrame(csv_entries16, columns=['ID', 'Authors', 'Title', 'Bibliography']))\n",
    "result_csv2 = result_csv1.append(pd.DataFrame(csv_entries17, columns=['ID', 'Authors', 'Title', 'Bibliography']))\n",
    "result_csv3 = result_csv2.append(pd.DataFrame(csv_entries18, columns=['ID', 'Authors', 'Title', 'Bibliography']))\n",
    "result_csv4 = result_csv3.append(pd.DataFrame(csv_entries19, columns=['ID', 'Authors', 'Title', 'Bibliography']))\n",
    "result_csv5 = result_csv4.append(pd.DataFrame(csv_entries20, columns=['ID', 'Authors', 'Title', 'Bibliography']))\n",
    "result_csv = result_csv5.append(pd.DataFrame(csv_entriesdhq, columns=['ID', 'Authors', 'Title', 'Bibliography']))\n",
    "result_csv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df=result_csv\n",
    "# test_df['n_references'] = [len(x) for x in test_df['Bibliography']]\n",
    "# test_df.sort_values('n_references').tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the papers having the TEI \\<bibl\\>   elements.\n",
    "\n",
    "The dataset contains 2788 documents structured according **TEI** document model.\n",
    "\n",
    "These documents are parsed to individuate those having the *\\<bibl\\>* (bibliographic citation) element, this element  contains a loosely-structured bibliographic description where the sub-components may or may not be explicitly tagged. There are 1624 documents having this element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=result_csv\n",
    "test_df['n_references'] = [len(x) for x in test_df['Bibliography']]\n",
    "#test_df.sort_values('n_references').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Title</th>\n",
       "      <th>Bibliography</th>\n",
       "      <th>n_references</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>000172</td>\n",
       "      <td>[]</td>\n",
       "      <td>Digital Humanities, Postfoundationalism, Posti...</td>\n",
       "      <td>[Adams, Melissa et al. Fembot Collective , 200...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>000144</td>\n",
       "      <td>[]</td>\n",
       "      <td>Taken Possession of: The Reprinting and Reauth...</td>\n",
       "      <td>[The Celestial Railroad. United States Magazin...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>000077</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Digital Future is Now: A Call to Action fo...</td>\n",
       "      <td>[Ainsworth, P. (2009). Virtual Vellum. Retriev...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>000201</td>\n",
       "      <td>[]</td>\n",
       "      <td>The Shock of the Familiar: Three Timelines abo...</td>\n",
       "      <td>[About AACR2. http://www.aacr2.org/about.html,...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>000111</td>\n",
       "      <td>[]</td>\n",
       "      <td>Pertinent Discussions Toward Modeling the Soci...</td>\n",
       "      <td>[Ovsiannikov, Ilia A., Michael A. Arbib, and T...</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Authors                                              Title  \\\n",
       "171  000172      []  Digital Humanities, Postfoundationalism, Posti...   \n",
       "143  000144      []  Taken Possession of: The Reprinting and Reauth...   \n",
       "76   000077      []  The Digital Future is Now: A Call to Action fo...   \n",
       "200  000201      []  The Shock of the Familiar: Three Timelines abo...   \n",
       "110  000111      []  Pertinent Discussions Toward Modeling the Soci...   \n",
       "\n",
       "                                          Bibliography  n_references  \n",
       "171  [Adams, Melissa et al. Fembot Collective , 200...           113  \n",
       "143  [The Celestial Railroad. United States Magazin...           120  \n",
       "76   [Ainsworth, P. (2009). Virtual Vellum. Retriev...           130  \n",
       "200  [About AACR2. http://www.aacr2.org/about.html,...           140  \n",
       "110  [Ovsiannikov, Ilia A., Michael A. Arbib, and T...           254  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv=result_csv[result_csv['Bibliography'].str.len()>1]\n",
    "#test_csv.count()\n",
    "test_csv.sort_values('n_references').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#com_test_csv[com_test_csv['n_references']==140].head().style.set_properties(subset=['Bibliography'], **{'width': '600px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              25115\n",
       "Title           25115\n",
       "Bibliography    25115\n",
       "dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all citations\n",
    "my_df=test_csv[['ID','Title','Bibliography']]\n",
    "my_exp_df_tmp_1=my_df.explode('Bibliography')\n",
    "# cleaning...\n",
    "my_exp_df= my_exp_df_tmp_1[(~my_exp_df_tmp_1['Bibliography'].str.startswith(\"DHQ classification\")) & (~my_exp_df_tmp_1['Bibliography'].str.startswith(\"Keywords supplied by author\"))\n",
    "                                & (~my_exp_df_tmp_1['Bibliography'].str.startswith(\"(accessed\")) & (~my_exp_df_tmp_1['Bibliography'].str.startswith(\"Enter your references here\"))]\n",
    "\n",
    "my_exp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Bibliography</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>000180</td>\n",
       "      <td>Escaping the Shallows: Deep Reading’s Revival ...</td>\n",
       "      <td>#1book140 (2014). #Outlander. 10 February. Ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>000198</td>\n",
       "      <td>Humanities Unbound: Supporting Careers and Sch...</td>\n",
       "      <td>#Alt-Academy (January 2011): http://mediacommo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>WALSH_Brandon_Digital_Humanities_Pedagogy_and_...</td>\n",
       "      <td>Digital Humanities Pedagogy and Praxis Roundtable</td>\n",
       "      <td>#FutureEd. Humanities, Arts, Science, and Tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>000208</td>\n",
       "      <td>Beyond the Margins: Intersectionality and the ...</td>\n",
       "      <td>#transformDH. About #transformDH. http://origi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>PUREN_M_P__The_Time_Us_project__Creating_gold_...</td>\n",
       "      <td>The Time-Us project. Creating gold data to und...</td>\n",
       "      <td>(2009). Extracting and Visualizing Quotations ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ID  \\\n",
       "179                                             000180   \n",
       "197                                             000198   \n",
       "322  WALSH_Brandon_Digital_Humanities_Pedagogy_and_...   \n",
       "207                                             000208   \n",
       "242  PUREN_M_P__The_Time_Us_project__Creating_gold_...   \n",
       "\n",
       "                                                 Title  \\\n",
       "179  Escaping the Shallows: Deep Reading’s Revival ...   \n",
       "197  Humanities Unbound: Supporting Careers and Sch...   \n",
       "322  Digital Humanities Pedagogy and Praxis Roundtable   \n",
       "207  Beyond the Margins: Intersectionality and the ...   \n",
       "242  The Time-Us project. Creating gold data to und...   \n",
       "\n",
       "                                          Bibliography  \n",
       "179  #1book140 (2014). #Outlander. 10 February. Ava...  \n",
       "197  #Alt-Academy (January 2011): http://mediacommo...  \n",
       "322  #FutureEd. Humanities, Arts, Science, and Tech...  \n",
       "207  #transformDH. About #transformDH. http://origi...  \n",
       "242  (2009). Extracting and Visualizing Quotations ...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_exp_tmp_df=my_exp_df[my_exp_df['Bibliography'].str.len()>0]\n",
    "my_exp_tmp_df.sort_values(\"Bibliography\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID              25096\n",
       "Title           25096\n",
       "Bibliography    25096\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_exp_tmp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cesare/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID              325\n",
       "Title           325\n",
       "Bibliography    325\n",
       "dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_exp_df_tmp=my_exp_df[my_exp_df['Bibliography'].str.len()>0]\n",
    "my_exp_df_tmp['Bibliography']=my_exp_df_tmp['Bibliography']\n",
    "df_temp_dupl=my_exp_df_tmp[my_exp_df_tmp.duplicated('Bibliography', keep='last')]\n",
    "#df_temp_dupl.sort_values('Bibliography').iloc[0:30]\n",
    "df_temp_dupl.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of citations individuated in the dataset is 25096."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find citations having a DOI\n",
    "*Regular expressions* are used to parse all citations in order to individuate those having a DOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " There are 6838 references with a URL \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regexu1=re.compile(\n",
    "       r\"((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*\"\n",
    "       )\n",
    "df_refs=my_exp_df.Bibliography.values\n",
    "df_refs_with_url = pd.DataFrame(columns=[\"Reference\", \"URL\"])\n",
    "ureferences=[]\n",
    "URLs=[]\n",
    "for ureference in df_refs:\n",
    "    myur=re.search(regexu1, ureference)\n",
    "    if myur:\n",
    "        ureferences.append(ureference);\n",
    "        URLs.append(myur[0]);\n",
    "        #print (ureference+'\\n'+myur[0], end=\"\\n\\n\")\n",
    "    #else:\n",
    "        #print (reference)\n",
    "df_refs_with_url['Reference']=ureferences;\n",
    "df_refs_with_url['URL']=URLs;\n",
    "df_refs_with_url.drop_duplicates(inplace=True)\n",
    "#df_refs_with_url.info()\n",
    "refwURL=df_refs_with_url.count()\n",
    "print (f'\\n There are {refwURL[1]} references with a URL \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " There are 1173 references with a DOI \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regex = re.compile(r'\\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![\"&\\'<>])\\S)+)\\b', re.IGNORECASE)\n",
    "#regex = re.compile(r'\\b(10.\\d{0,}/[-._;()/:A-Z0-9])\\b', re.IGNORECASE)\n",
    "#regex = re.compile(\n",
    "#        r'/^10.\\d{4,9}/[-._;()/:A-Z0-9]+$/i'\n",
    "#        r'/^10.1002/[^\\s]+$/i'\n",
    "#        r'/^10.\\d{4}/\\d+-\\d+X?(\\d+)\\d+<[\\d\\w]+:[\\d\\w]*>\\d+.\\d+.\\w+;\\d$/i'\n",
    "#        r'/^10.1021/\\w\\w\\d+$/i'\n",
    "#        r'/^10.1207/[\\w\\d]+\\&\\d+_\\d+$/i', re.IGNORECASE)\n",
    "df_refs=my_exp_df.Bibliography.values\n",
    "df_refs_with_doi = pd.DataFrame(columns=[\"Reference\", \"DOI\"])\n",
    "references=[]\n",
    "DOIs=[]\n",
    "for reference in df_refs:\n",
    "    mydoi=re.search(regex, reference)\n",
    "    if mydoi:\n",
    "        references.append(reference);\n",
    "        DOIs.append(mydoi[0]);\n",
    "        #print (reference+'\\n'+mydoi[0], end=\"\\n\\n\")\n",
    "df_refs_with_doi['Reference']=references;\n",
    "df_refs_with_doi['DOI']=DOIs;\n",
    "df_refs_with_doi.drop_duplicates(inplace=True)\n",
    "refwDOI=df_refs_with_doi.count()\n",
    "print (f'\\n There are {refwDOI[1]} references with a DOI \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_08896668_8c08_11eb_94b3_60f81dca6224row0_col0,#T_08896668_8c08_11eb_94b3_60f81dca6224row1_col0,#T_08896668_8c08_11eb_94b3_60f81dca6224row2_col0,#T_08896668_8c08_11eb_94b3_60f81dca6224row3_col0,#T_08896668_8c08_11eb_94b3_60f81dca6224row4_col0{\n",
       "            width:  600px;\n",
       "        }</style><table id=\"T_08896668_8c08_11eb_94b3_60f81dca6224\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Reference</th>        <th class=\"col_heading level0 col1\" >DOI</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_08896668_8c08_11eb_94b3_60f81dca6224level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_08896668_8c08_11eb_94b3_60f81dca6224row0_col0\" class=\"data row0 col0\" >Byrne, G., and Goddard, L. (2010). The Strongest Link: Libraries and Linked Data. D-Lib Magazine , 16 (11/12), doi:10.1045/november2010-byrne.</td>\n",
       "                        <td id=\"T_08896668_8c08_11eb_94b3_60f81dca6224row0_col1\" class=\"data row0 col1\" >10.1045/november2010-byrne</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08896668_8c08_11eb_94b3_60f81dca6224level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_08896668_8c08_11eb_94b3_60f81dca6224row1_col0\" class=\"data row1 col0\" >Lampert, C. K., and Southwick, S. B. (2013). Leading to Linking: Introducing Linked Data to Academic Library Digital Collections. Journal of Library Metadata , 13 (2–3): 230–53, doi:10.1080/19386389.2013.826095.</td>\n",
       "                        <td id=\"T_08896668_8c08_11eb_94b3_60f81dca6224row1_col1\" class=\"data row1 col1\" >10.1080/19386389.2013.826095</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08896668_8c08_11eb_94b3_60f81dca6224level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_08896668_8c08_11eb_94b3_60f81dca6224row2_col0\" class=\"data row2 col0\" >Singer, R. (2009). Linked Library Data Now! Journal of Electronic Resources Librarianship , 21 (2): 114–26, doi:10.1080/19411260903035809.</td>\n",
       "                        <td id=\"T_08896668_8c08_11eb_94b3_60f81dca6224row2_col1\" class=\"data row2 col1\" >10.1080/19411260903035809</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08896668_8c08_11eb_94b3_60f81dca6224level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_08896668_8c08_11eb_94b3_60f81dca6224row3_col0\" class=\"data row3 col0\" >Thomas, L. and Solomon, D. (2014). Active Users: Project Development and Digital Humanities Pedagogy. CEA Critic, 76 (2) (July): 211–20, DOI:10.1353/cea.2014.0014.</td>\n",
       "                        <td id=\"T_08896668_8c08_11eb_94b3_60f81dca6224row3_col1\" class=\"data row3 col1\" >10.1353/cea.2014.0014</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_08896668_8c08_11eb_94b3_60f81dca6224level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_08896668_8c08_11eb_94b3_60f81dca6224row4_col0\" class=\"data row4 col0\" >Farquhar, A. and Baker, J. (2014). Interoperable Infrastructures for Digital Research: A Proposed Pathway for Enabling Transformation. Digital Humanities 2014, http://dx.doi.org/10.6084/m9.figshare.1092550%20.</td>\n",
       "                        <td id=\"T_08896668_8c08_11eb_94b3_60f81dca6224row4_col1\" class=\"data row4 col1\" >10.6084/m9.figshare.1092550%20</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x122f74210>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example: five citations that have DOIs\n",
    "df_refs_with_doi.head()\n",
    "df_refs_with_doi.head().style.set_properties(subset=['Reference'], **{'width': '600px'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check DOIs\n",
    "\n",
    "To check if there are errors, the DOIs are invoked and the HTTP Return Status is checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_http_status=get_HTTP_Status(df_refs_with_doi.DOI.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOIs HTTP Return Status: 404 Not Found\n",
    "\n",
    "References where DOIs return *404 Not Found*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DOI          30\n",
       "status       30\n",
       "Reference    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_404=df_http_status[df_http_status['status'] == 404]\n",
    "test=df_404.join(df_refs_with_doi.set_index('DOI'), on='DOI')\n",
    "test1=test.drop_duplicates(subset='DOI', keep=\"last\")\n",
    "test1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row0_col2,#T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row1_col2,#T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row2_col2,#T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row3_col2{\n",
       "            width:  600px;\n",
       "        }</style><table id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >DOI</th>        <th class=\"col_heading level0 col1\" >status</th>        <th class=\"col_heading level0 col2\" >Reference</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224level0_row0\" class=\"row_heading level0 row0\" >26</th>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row0_col0\" class=\"data row0 col0\" >10.1002/9781405177504.ch28/summary</td>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row0_col1\" class=\"data row0 col1\" >404</td>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row0_col2\" class=\"data row0 col2\" >Hoover, D. L. (2013). Quantitative Analysis and Literary Studies. In R. Siemens & S. Schreibman (Eds.), A Companion to Digital Literary Studies (pp. 517–533). John Wiley & Sons, Ltd. Retrieved from http://onlinelibrary.wiley.com/doi/10.1002/9781405177504.ch28/summary</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224level0_row1\" class=\"row_heading level0 row1\" >27</th>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row1_col0\" class=\"data row1 col0\" >10.1002/9780470999875.ch</td>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row1_col1\" class=\"data row1 col1\" >404</td>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row1_col2\" class=\"data row1 col2\" >McCarty, Willard. Modeling. A Study in Words and Meanings. In Schreibman, Susan, Siemens, Ray et Unsworth, John (éd.). A Companion to Digital Humanities. Willey (2004). DOI: 10.1002/9780470999875.ch 19</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224level0_row2\" class=\"row_heading level0 row2\" >28</th>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row2_col0\" class=\"data row2 col0\" >10.1207/s15327051hci1304</td>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row2_col1\" class=\"data row2 col1\" >404</td>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row2_col2\" class=\"data row2 col2\" >Dourish, Paul, and Graham Button. 1998. On ‘Technomethodology’: Foundational Relationships between Ethnomethodology and System Design. Human-Computer Interaction 13 (4): 395–432. https://doi.org/10.1207/s15327051hci1304.</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224level0_row3\" class=\"row_heading level0 row3\" >29</th>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row3_col0\" class=\"data row3 col0\" >10.1007/978-3-642-39209-2-20</td>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row3_col1\" class=\"data row3 col1\" >404</td>\n",
       "                        <td id=\"T_6d31d8d0_8c0c_11eb_94b3_60f81dca6224row3_col2\" class=\"data row3 col2\" >Al-Omar, M., & Cox, A. (2013). Finders, Keepers, Losers, Seekers: A Study of Academics' Research-Related Personal Information Collections. Lecture Notes in Computer Science, 8016 LNCS (PART 1), 169–176. doi:10.1007/978-3-642-39209-2-20</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1230ead10>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of DOIs returning 404\n",
    "test.drop_duplicates(subset='DOI', keep='first').reset_index(drop=True).tail(4).style.set_properties(subset=['Reference'], **{'width': '600px'})\n",
    "#test.to_csv(path_or_buf='../data/notfound.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve citation DOIs using CrossRef API\n",
    "Crossref API allows [querying the database by giving it in input strings that contain bibliography references](https://www.crossref.org/labs/resolving-citations-we-dont-need-no-stinkin-parser/). The reference string does not to be necessarily a well-written references. The input string is parsed by Crossref using machine learning techniques and the system tries to match the reference string with the metadata that are stored in the database. \n",
    "\n",
    "An important feature of Crossref API, is the score of sureness that Crossref API retrieve beside the document’s metadata. For each request, Crossref score indicates how much it is sure about the entities retrieved, if the score value is high the metadata retrieved are probably correct, if the score is low the metadata retrieved might be the wrong ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the Crossref query API is used to check if citations whose DOI http connection returns *404 Not Found* can be found in the Crossref Database and, if yes, to find what is the correct DOI. The value *110* is the minimum score value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json\n",
    "references=test1['Reference'];\n",
    "df_citations404 = pd.DataFrame(columns=[\"Publication_cit\", \"Crossref_cit_title\", \"Crossref_cit_author\", \"Crossref_cit_metadata\", \"Crossref_DOI\"])\n",
    "originalCitations=[]\n",
    "crossrefCitations=[]\n",
    "crossrefCitationsAuthor=[]\n",
    "crossrefCitationsMetadata=[]\n",
    "DOIs=[]\n",
    "score=[]\n",
    "i=0;\n",
    "j =0;\n",
    "for citenf in references:\n",
    "    cit=urllib.parse.quote_plus(citenf)\n",
    "    try:\n",
    "        with urllib.request.urlopen(\"https://api.crossref.org/works?query.bibliographic=\"+cit+\"&sort=score&mailto=cesare.concordia@gmail.com#\", timeout=18000) as url:\n",
    "            data16 = json.loads(url.read().decode())\n",
    "            j=j+1\n",
    "            if (j%5 == 0):\n",
    "                print(f\"{j}, ({i})\")\n",
    "            if (len(data16[\"message\"][\"items\"])>0) and (data16[\"message\"][\"items\"][0]['score'] >110):\n",
    "                originalCitations.append(citenf)\n",
    "                crossrefCitationsMetadata.append( data16[\"message\"][\"items\"][0])\n",
    "                crossrefCitations.append( data16[\"message\"][\"items\"][0]['title'])\n",
    "                crossrefCitationsAuthor.append( data16[\"message\"][\"items\"][0]['author'])\n",
    "                DOIs.append(data16[\"message\"][\"items\"][0]['DOI'])\n",
    "                score.append(data16[\"message\"][\"items\"][0]['score'])\n",
    "                i=i+1\n",
    "                #print(f\"{i} found, out of {j}\")\n",
    "            if (j>1000):\n",
    "                break\n",
    "    except urllib.error.URLError:\n",
    "        print(cit)\n",
    "    except urllib.error.HTTPError:\n",
    "        print(cit)\n",
    "        \n",
    "df_citations404[\"Publication_cit\"] = originalCitations\n",
    "df_citations404[\"Crossref_cit_title\"] = crossrefCitations\n",
    "df_citations404[\"Crossref_cit_author\"] = crossrefCitationsAuthor\n",
    "df_citations404[\"Crossref_cit_metadata\"] = crossrefCitationsMetadata\n",
    "df_citations404[\"Crossref_DOI\"] = DOIs\n",
    "df_citations404[\"Score\"] = score\n",
    "#df_citations404.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Crossref API, 10 DOIs have been found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Publication_cit          10\n",
       "Crossref_cit_title       10\n",
       "Crossref_cit_author      10\n",
       "Crossref_cit_metadata    10\n",
       "Crossref_DOI             10\n",
       "Score                    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_citations404.count()\n",
    "#df_citations404[['Publication_cit', 'Crossref_cit_title', 'Crossref_cit_author', 'Crossref_DOI']].head(10).style.set_properties(subset=['Publication_cit'], **{'width': '200px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_citations404.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_09220760_8c0d_11eb_94b3_60f81dca6224row0_col0,#T_09220760_8c0d_11eb_94b3_60f81dca6224row0_col1,#T_09220760_8c0d_11eb_94b3_60f81dca6224row1_col0,#T_09220760_8c0d_11eb_94b3_60f81dca6224row1_col1,#T_09220760_8c0d_11eb_94b3_60f81dca6224row2_col0,#T_09220760_8c0d_11eb_94b3_60f81dca6224row2_col1,#T_09220760_8c0d_11eb_94b3_60f81dca6224row3_col0,#T_09220760_8c0d_11eb_94b3_60f81dca6224row3_col1,#T_09220760_8c0d_11eb_94b3_60f81dca6224row4_col0,#T_09220760_8c0d_11eb_94b3_60f81dca6224row4_col1,#T_09220760_8c0d_11eb_94b3_60f81dca6224row5_col0,#T_09220760_8c0d_11eb_94b3_60f81dca6224row5_col1,#T_09220760_8c0d_11eb_94b3_60f81dca6224row6_col0,#T_09220760_8c0d_11eb_94b3_60f81dca6224row6_col1,#T_09220760_8c0d_11eb_94b3_60f81dca6224row7_col0,#T_09220760_8c0d_11eb_94b3_60f81dca6224row7_col1,#T_09220760_8c0d_11eb_94b3_60f81dca6224row8_col0,#T_09220760_8c0d_11eb_94b3_60f81dca6224row8_col1,#T_09220760_8c0d_11eb_94b3_60f81dca6224row9_col0,#T_09220760_8c0d_11eb_94b3_60f81dca6224row9_col1{\n",
       "            width:  200px;\n",
       "        }</style><table id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Publication_cit</th>        <th class=\"col_heading level0 col1\" >Crossref_cit_title</th>        <th class=\"col_heading level0 col2\" >Crossref_cit_author</th>        <th class=\"col_heading level0 col3\" >DOI</th>        <th class=\"col_heading level0 col4\" >Crossref_DOI</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row0_col0\" class=\"data row0 col0\" >Griffiths Mary and Kim Barbour. \"‘Imagine If Our Cities Talked to Us’: Questions about the Making of ‘responsive’ Places and Urban Publics.\" In Making Publics, Making Places, 27-48. South Australia: University of Adelaide Press, 2016, http://www.jstor.org/stable/10.20851/j.ctt1t304qd.8</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row0_col1\" class=\"data row0 col1\" >[\"'Imagine if our cities talked to us': Questions about the making of 'responsive' places and urban publics\"]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row0_col2\" class=\"data row0 col2\" >[{'given': 'Mary', 'family': 'Griffiths', 'sequence': 'first', 'affiliation': []}]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row0_col3\" class=\"data row0 col3\" >10.20851/j.ctt1t304qd.8</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row0_col4\" class=\"data row0 col4\" >10.20851/publics-03</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row1_col0\" class=\"data row1 col0\" >Underwood, T., Bamman, D. and Lee, S. (2018). The transformation of Gender in English language fiction. Cultural Analytics, http://culturalanalytics.org/2018/02/thetransformation-of-gender-in-english-language-fiction/ (DOI: 10.7910/DVN/TEGMGI)</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row1_col1\" class=\"data row1 col1\" >['The Transformation of Gender in English-Language Fiction']</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row1_col2\" class=\"data row1 col2\" >[{'given': 'Ted', 'family': 'Underwood', 'sequence': 'first', 'affiliation': []}, {'given': 'David', 'family': 'Bamman', 'sequence': 'additional', 'affiliation': []}, {'given': 'Sabrina', 'family': 'Lee', 'sequence': 'additional', 'affiliation': []}]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row1_col3\" class=\"data row1 col3\" >10.7910/DVN/TEGMGI</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row1_col4\" class=\"data row1 col4\" >10.22148/16.019</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row2_col0\" class=\"data row2 col0\" >Bates, M. (1998). Indexing and access for digital libraries and the Internet: human, database, and domain factors. Journal of the American Society for Information Science , 49 (13) doi:10.1002/(SICI)1097-4571(1998110)49:13<1185::AID-ASI6>3.3.CO;2-M (accessed 23 March 2011).</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row2_col1\" class=\"data row2 col1\" >['Indexing and access for digital libraries and the internet: Human, database, and domain factors']</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row2_col2\" class=\"data row2 col2\" >[{'given': 'Marcia J.', 'family': 'Bates', 'sequence': 'first', 'affiliation': []}]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row2_col3\" class=\"data row2 col3\" >10.1002/(SICI)1097-4571(1998110)49:13</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row2_col4\" class=\"data row2 col4\" >10.1002/(sici)1097-4571(1998110)49:13<1185::aid-asi6>3.0.co;2-v</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row3_col0\" class=\"data row3 col0\" >Spiro, L. (2012). “This Is Why We Fight”: Defining the Values of the Digital Humanities. In M. K. Gold (ed.), Debates in the Digital Humanities. University of Minnesota Press, pp. 16–35. Available at http://minnesota.universitypressscholarship.com/view/10.5749/minnesota/9780816677948.001.0001/upso-9780816677948-chapter-3</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row3_col1\" class=\"data row3 col1\" >['“This Is Why We Fight”: Defining the Values of the Digital Humanities']</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row3_col2\" class=\"data row3 col2\" >[{'given': 'Lisa', 'family': 'Spiro', 'sequence': 'first', 'affiliation': []}]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row3_col3\" class=\"data row3 col3\" >10.5749/minnesota/9780816677948.001.0001/upso-9780816677948-chapter-3</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row3_col4\" class=\"data row3 col4\" >10.5749/minnesota/9780816677948.003.0003</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row4_col0\" class=\"data row4 col0\" >Shapiro, L. A. (2012). Embodied Cognition. In Margolis, E., Samuels, R., and Stich, S. P. (eds.), The Oxford Handbook of Philosophy of Cognitive Science. Oxford, New York: Oxford University Press, pp. 118–46. http://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780195309799.001.0001/oxfordhb-9780195309799-e-6 (accessed 26 November 2018).</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row4_col1\" class=\"data row4 col1\" >['6. Embodied Cognition']</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row4_col2\" class=\"data row4 col2\" >[{'given': 'Lawrence A.', 'family': 'Shapiro', 'sequence': 'first', 'affiliation': []}]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row4_col3\" class=\"data row4 col3\" >10.1093/oxfordhb/9780195309799.001.0001/oxfordhb-9780195309799-e-6</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row4_col4\" class=\"data row4 col4\" >10.1093/oxfordhb/9780195309799.003.0006</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row5_col0\" class=\"data row5 col0\" >Hirsch, Brett D., 2011. The Kingdom Has Been Digitized: Electronic Editions of Renaissance Drama and the Long Shadows of Shakespeare and Print. Literature Compass [online] 8 (9): 568-591. Available from: http://onlinelibrary.wiley.com/doi/10.1111/lico.2011.8.issue-9/issuetoc [Accessed 27 September 2012].</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row5_col1\" class=\"data row5 col1\" >['The Kingdom has been Digitized: Electronic Editions of Renaissance Drama and the Long Shadows of Shakespeare and Print']</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row5_col2\" class=\"data row5 col2\" >[{'given': 'Brett D.', 'family': 'Hirsch', 'sequence': 'first', 'affiliation': []}]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row5_col3\" class=\"data row5 col3\" >10.1111/lico.2011.8.issue-9/issuetoc</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row5_col4\" class=\"data row5 col4\" >10.1111/j.1741-4113.2011.00830.x</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row6_col0\" class=\"data row6 col0\" >Romanello, Matteo. 2013. Creating an Annotated Corpus for Extracting Canonical Citations from Classics-Related Texts by Using Active Annotation. In Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013, Samos, Greece, March 24-30, 2013, Proceedings, Part I , edited by Alexander Gelbukh, 1:60–76. Lecture Notes in Computer Science / Theoretical Computer Science and General Issues. Springer Berlin Heidelberg. doi:10.1007/978-3-642-37247-6\\_6. http://doi.org/10.1007/978-3-642-37247-6\\_6</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row6_col1\" class=\"data row6 col1\" >['Creating an Annotated Corpus for Extracting Canonical Citations from Classics-Related Texts by Using Active Annotation']</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row6_col2\" class=\"data row6 col2\" >[{'given': 'Matteo', 'family': 'Romanello', 'sequence': 'first', 'affiliation': []}]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row6_col3\" class=\"data row6 col3\" >10.1007/978-3-642-37247-6\\_6</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row6_col4\" class=\"data row6 col4\" >10.1007/978-3-642-37247-6_6</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row7_col0\" class=\"data row7 col0\" >Zundert, van, J.J., 2016. Screwmeneutics and Hermenumericals: the Computationality of Hermeneutics. In S. Schreibman, R. Siemens, & J. Unsworth, eds. A New Companion to Digital Humanities. Malden (US), Oxford (UK), etc.: John Wiley & Sons, Ltd, pp. 331–347. Available at: http://onlinelibrary.wiley.com/doi/10.1002/9781118680605.ch23/summary [Accessed July 26, 2016].</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row7_col1\" class=\"data row7 col1\" >['Screwmeneutics and Hermenumericals']</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row7_col2\" class=\"data row7 col2\" >[{'given': 'Joris J.', 'family': 'van Zundert', 'sequence': 'first', 'affiliation': []}]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row7_col3\" class=\"data row7 col3\" >10.1002/9781118680605.ch23/summary</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row7_col4\" class=\"data row7 col4\" >10.1002/9781118680605.ch23</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row8_col0\" class=\"data row8 col0\" >Hoover, D. L. (2013). Quantitative Analysis and Literary Studies. In R. Siemens & S. Schreibman (Eds.), A Companion to Digital Literary Studies (pp. 517–533). John Wiley & Sons, Ltd. Retrieved from http://onlinelibrary.wiley.com/doi/10.1002/9781405177504.ch28/summary</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row8_col1\" class=\"data row8 col1\" >['Quantitative Analysis and Literary Studies']</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row8_col2\" class=\"data row8 col2\" >[{'given': 'David L.', 'family': 'Hoover', 'sequence': 'first', 'affiliation': []}]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row8_col3\" class=\"data row8 col3\" >10.1002/9781405177504.ch28/summary</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row8_col4\" class=\"data row8 col4\" >10.1002/9781405177504.ch28</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row9_col0\" class=\"data row9 col0\" >Dourish, Paul, and Graham Button. 1998. On ‘Technomethodology’: Foundational Relationships between Ethnomethodology and System Design. Human-Computer Interaction 13 (4): 395–432. https://doi.org/10.1207/s15327051hci1304.</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row9_col1\" class=\"data row9 col1\" >['On \"Technomethodology\": Foundational Relationships Between Ethnomethodology and System Design']</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row9_col2\" class=\"data row9 col2\" >[{'given': 'Paul', 'family': 'Dourish', 'sequence': 'first', 'affiliation': []}, {'given': 'Graham', 'family': 'Button', 'sequence': 'additional', 'affiliation': []}]</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row9_col3\" class=\"data row9 col3\" >10.1207/s15327051hci1304</td>\n",
       "                        <td id=\"T_09220760_8c0d_11eb_94b3_60f81dca6224row9_col4\" class=\"data row9 col4\" >10.1207/s15327051hci1304_2</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1231d2d90>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved404=df_citations404.join(test.set_index('Reference'), on='Publication_cit',  lsuffix='_in_publication')\n",
    "retrieved404[['Publication_cit', 'Crossref_cit_title', 'Crossref_cit_author', 'DOI', 'Crossref_DOI']].head(10).style.set_properties(subset=['Publication_cit','Crossref_cit_title'], **{'width': '200px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10.20851/publics-03', '10.22148/16.019',\n",
       "       '10.1002/(sici)1097-4571(1998110)49:13<1185::aid-asi6>3.0.co;2-v',\n",
       "       '10.5749/minnesota/9780816677948.003.0003',\n",
       "       '10.1093/oxfordhb/9780195309799.003.0006',\n",
       "       '10.1111/j.1741-4113.2011.00830.x', '10.1007/978-3-642-37247-6_6',\n",
       "       '10.1002/9781118680605.ch23', '10.1002/9781405177504.ch28',\n",
       "       '10.1207/s15327051hci1304_2'], dtype=object)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved404.Crossref_DOI.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 10.20851/publics-03  200\n",
      "result: 10.22148/16.019  200\n",
      "result: 10.1002/(sici)1097-4571(1998110)49:13<1185::aid-asi6>3.0.co;2-v  403\n",
      "result: 10.1111/j.1741-4113.2011.00830.x  403\n",
      "result: 10.1007/978-3-642-37247-6_6  200\n",
      "result: 10.1002/9781118680605.ch23  403\n",
      "result: 10.1002/9781405177504.ch28  403\n",
      "result: 10.1207/s15327051hci1304_2  200\n"
     ]
    }
   ],
   "source": [
    "dfdc=get_HTTP_Status(retrieved404.Crossref_DOI.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403    4\n",
       "200    4\n",
       "408    2\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdc_st = dfdc['status'].value_counts()\n",
    "dfdc_st.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 retrieved DOIs are valid (HTTP 403 is a HTTP status code meaning that he server understood the request, but will not fulfill it due to client-related issues), 2 of them returns connection timeout status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdc_t=dfdc.join(retrieved404[['Publication_cit', 'Crossref_DOI']].set_index('Crossref_DOI'), on='DOI',  lsuffix='_')\n",
    "dfdc_t.head(10).style.set_properties(subset=['Publication_cit'], **{'width': '300px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
